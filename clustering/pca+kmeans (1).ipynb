{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pca+kmeans.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3544uog_yldu"
      },
      "source": [
        "This code uses Principal Component Analysis (to reduce dimensionality) and k-means clustering to group similar 'hit' songs together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUhevV0SNPHY"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import io\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY4Yb07HNUKe",
        "outputId": "9b1da0cd-0884-414c-c3c2-802f3b52b9dc"
      },
      "source": [
        "# Downloading the csv file from our GitHub repo\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Jingxue-24/QM2-team9/main/Spotify%20API/merged.csv\"\n",
        "download = requests.get(url).content\n",
        "\n",
        "# Reading the downloaded content and turning it into a pandas dataframe\n",
        "\n",
        "df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "\n",
        "# Previewing data\n",
        "\n",
        "print (df.head())\n",
        "print(df.columns)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 Name  ... Time_signature\n",
            "0          Bridge Over Troubled Water  ...              4\n",
            "1      (They Long To Be) Close To You  ...              4\n",
            "2  American Woman - 7\" Single Version  ...              4\n",
            "3                War - Single Version  ...              4\n",
            "4       Ain't No Mountain High Enough  ...              4\n",
            "\n",
            "[5 rows x 17 columns]\n",
            "Index(['Name', 'Album', 'Artist', 'Popular_date', 'Release_date', 'Length',\n",
            "       'Popularity', 'Danceability', 'Acousticness', 'Danceability.1',\n",
            "       'Energy', 'Instrumentalness', 'Liveness', 'Loudness', 'Speechiness',\n",
            "       'Tempo', 'Time_signature'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJsdiQRyzwp"
      },
      "source": [
        "All works well. Moving on to prepping the data for PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ElMt3_LcWtP",
        "outputId": "7aa1c34e-0c96-4251-d4bf-44c1923d260f"
      },
      "source": [
        "df.drop(['Name', 'Album', 'Artist','Popular_date','Release_date', 'Popularity', 'Danceability.1', 'Liveness'], axis=1, inplace=True)\n",
        "print(df.columns)  \n",
        "print(df.head()) \n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Length', 'Danceability', 'Acousticness', 'Energy', 'Instrumentalness',\n",
            "       'Loudness', 'Speechiness', 'Tempo', 'Time_signature'],\n",
            "      dtype='object')\n",
            "   Length  Danceability  Acousticness  ...  Speechiness    Tempo  Time_signature\n",
            "0  293120         0.149        0.8220  ...       0.0323   79.764               4\n",
            "1  276000         0.543        0.6690  ...       0.0344   89.078               4\n",
            "2  231640         0.538        0.0424  ...       0.0375   93.077               4\n",
            "3  200960         0.591        0.0677  ...       0.1920  109.481               4\n",
            "4  215200         0.393        0.1910  ...       0.0448   98.757               4\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSlHY2zIy61J"
      },
      "source": [
        "All works well. Moving on to Kaiser-Meyer-Olkin test for suitability of data for PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-nB5h2_OJos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "0e0d478e-8742-45ca-fab2-3512e9a6a680"
      },
      "source": [
        "# KMO test\n",
        "from factor_analyzer.factor_analyzer import calculate_kmo\n",
        "kmo_all, kmo_model = calculate_kmo(df)\n",
        "kmo_model # = 0.5958992986526002 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a2f624275202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# KMO test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfactor_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor_analyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_kmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkmo_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_kmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkmo_model\u001b[0m \u001b[0;31m# = 0.5958992986526002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'factor_analyzer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGphLArGzEXC"
      },
      "source": [
        "Not a great KMO value - \"miserable\". We will have to discuss this in the website. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UspU3HjKNe7J"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#Standardising data\n",
        "std_df = StandardScaler().fit_transform(df) #normalizing\n",
        "\n",
        "#PCA\n",
        "pca = PCA(n_components=9)\n",
        "principalComponents = pca.fit_transform(std_df)\n",
        "\n",
        "#Plotting the variances for each PC\n",
        "PC = range(1, pca.n_components_+1)\n",
        "fig, ax = plt.subplots(figsize=(8,8)) # width & height \n",
        "plt.bar(PC, pca.explained_variance_ratio_, color='gold')\n",
        "ax.set(title=\"How much variance is explained by PCs\", xlabel=\"Principal Components\", ylabel=\"Variance %\")\n",
        "plt.xticks(PC)\n",
        "\n",
        "#Putting it in a dataframe\n",
        "PCA_components = pd.DataFrame(principalComponents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrwq8cUgzhPo"
      },
      "source": [
        "First principal component explains over 25% of the variance. Second explains approximately 13%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPbrL0g2O9If"
      },
      "source": [
        "plt.scatter(PCA_components[0], PCA_components[1], alpha=.3, color='gold')\n",
        "plt.xlabel=('PCA 1')\n",
        "plt.ylabel=('PCA 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8JariW0zuEe"
      },
      "source": [
        "Now, we need to use k-means to see how many clusters there actually are. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Un8KOpOcSK"
      },
      "source": [
        "# Clustering - seeing exactly how many there are. \n",
        "inertias = []\n",
        "\n",
        "for k in range(1,10):\n",
        "  model = KMeans(n_clusters=k)\n",
        "\n",
        "  model.fit(PCA_components.iloc[:,:3])\n",
        "\n",
        "  inertias.append(model.inertia_)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,8)) # width & height \n",
        "plt.plot(range(1,10), inertias, '-p', color='gold')\n",
        "ax.set(title=\"Elbow Method for Optimal Number of k\", xlabel=\"k\", ylabel=\"Sum of Squared Distances\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc2SOIgNz3E-"
      },
      "source": [
        "Elbow method suggests 3 groupings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWxyCIKe79v"
      },
      "source": [
        "model = KMeans(n_clusters=3)\n",
        "model.fit(PCA_components.iloc[:,:2])\n",
        "labels = model.predict(PCA_components.iloc[:,:2])\n",
        "colormap = np.array(['r', 'g', 'b'])\n",
        "fig, ax = plt.subplots(figsize=(8,8)) # width & height \n",
        "plt.scatter(PCA_components[0], PCA_components[1], c=colormap[labels])\n",
        "ax.set(title=\"K-Means Clustering on Principal Components\", \n",
        "        xlabel=\"Principal Component 1\",\n",
        "        ylabel=\"Principal Component 2\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckde3PJSfO_s"
      },
      "source": [
        "# Adding the the cluster number to the original csv file. \n",
        "\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "y_kmeans = kmeans.fit_predict(std_df)\n",
        "\n",
        "kmeans = pd.DataFrame(data=y_kmeans, dtype=int)\n",
        "kmeans.columns=['k_cluster']\n",
        "print(kmeans.shape)\n",
        "kmeans.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JckjKNKcfxc5"
      },
      "source": [
        "# Downloading the original full csv file from our GitHub repo\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Jingxue-24/QM2-team9/main/merged.csv\"\n",
        "download = requests.get(url).content\n",
        "full_df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
        "full_df.drop(['Release_date','Popularity', 'Danceability.1'], axis=1, inplace=True)\n",
        "# Concatenating\n",
        "df_cluster = pd.concat([full_df, kmeans], axis=1)\n",
        "print(df_cluster.shape)\n",
        "df_cluster.head() # it works - have the cluster with the name of the song. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBuu3KhZhUI2"
      },
      "source": [
        "# Check for null\n",
        "df_cluster.isnull().sum() #no nulls!\n",
        "\n",
        "#Number of songs per cluster\n",
        "df_cluster['k_cluster'].value_counts()\n",
        "\n",
        "# Statistical distribution of the data in each column, for each cluster \n",
        "df_cluster.groupby(\"k_cluster\").describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYm95AZRs8Jg"
      },
      "source": [
        "# Updated datasets\n",
        "cluster_zero = df_cluster.loc[df_cluster['k_cluster']==0]\n",
        "cluster_one = df_cluster.loc[df_cluster['k_cluster']==1]\n",
        "cluster_two = df_cluster.loc[df_cluster['k_cluster']==2]\n",
        "\n",
        "# Exporting\n",
        "cluster_zero.to_csv('cluster_zero.csv', index=False, header=True)\n",
        "cluster_one.to_csv('cluster_one.csv', index=False, header=True)\n",
        "cluster_two.to_csv('cluster_two.csv', index=False, header=True)\n",
        "df_cluster.to_csv('cluster_all.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBkWUxUI8UBo"
      },
      "source": [
        "Now, summarising the three clusters. \n",
        "\n",
        "First, scatter plots between three audio features - acousticness, length and tempo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XstGzsw8XUn"
      },
      "source": [
        "# Reading the files\n",
        "k_zero = pd.read_csv('cluster_zero.csv')\n",
        "k_one = pd.read_csv('cluster_one.csv')\n",
        "k_two = pd.read_csv('cluster_two.csv')\n",
        "k_all = pd.read_csv('cluster_all.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Q87fhpjvCf"
      },
      "source": [
        "# Scatter for k_all - acoustic and length\n",
        "import plotly.express as px\n",
        "fig = px.scatter(k_all, x=\"Acousticness\", y=\"Length\", color='k_cluster',\n",
        "                 size='Tempo', hover_name=\"Name\", hover_data=[\"Artist\"], labels={'k_cluster':'Cluster'})\n",
        "fig.show()\n",
        "\n",
        "# Export as html for website\n",
        "fig.write_html(\"./k_all_acoustic_length.html\", include_plotlyjs='cdn') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z6_nCYvL2oX"
      },
      "source": [
        "Comparing the spread of years of the songs in each of the three clusters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ms6ZO86M4wO"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "k0_cols = k_zero[\"Popular_date\"]\n",
        "k1_cols = k_one[\"Popular_date\"]\n",
        "k2_cols = k_two[\"Popular_date\"]\n",
        "\n",
        "fig = go.Figure()\n",
        "# Using x instead of y argument for horizontal plot\n",
        "fig.add_trace(go.Box(x=k0_cols, name=\"Cluster Zero\"))\n",
        "fig.add_trace(go.Box(x=k1_cols, name=\"Cluster One\"))\n",
        "fig.add_trace(go.Box(x=k2_cols, name=\"Cluster Two\"))\n",
        " \n",
        "fig.show()\n",
        "\n",
        "# Export as html for website\n",
        "fig.write_html(\"./cluster_years_spread.html\", include_plotlyjs='cdn') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ez7OLvhRq_b"
      },
      "source": [
        "# Scatter for k_all - dance and energy\n",
        "fig = px.scatter(k_all, x=\"Danceability\", y=\"Energy\", color='k_cluster',\n",
        "                 size='Tempo', hover_name=\"Name\", hover_data=[\"Artist\"], labels={'k_cluster':'Cluster'})\n",
        "fig.show()\n",
        "\n",
        "# Export as html for website\n",
        "fig.write_html(\"./k_all_dance_energy.html\", include_plotlyjs='cdn') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzl4wyEiZLxr"
      },
      "source": [
        "Tutorial(s) used:\n",
        "\n",
        "\n",
        "*   https://medium.com/@dmitriy.kavyazin/principal-component-analysis-and-k-means-clustering-to-visualize-a-high-dimensional-dataset-577b2a7a5fe2 \n",
        "*   https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
        "*   https://plotly.com/python/ \n",
        "*   https://towardsdatascience.com/machine-learning-algorithms-part-9-k-means-example-in-python-f2ad05ed5203 \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}